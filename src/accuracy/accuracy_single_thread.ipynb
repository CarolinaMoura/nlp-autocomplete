{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from datasets import load_dataset\n",
    "from transformers import BertTokenizer, BertForMaskedLM\n",
    "from tqdm import tqdm\n",
    "from dijkstra.predictions import create_functions\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# brazilian alphabet\n",
    "lower_case = r'abcdefghijklmnopqrstuvwxyzáàâãéêíóôõúç'\n",
    "upper_case = r'ABCDEFGHIJKLMNOPQRSTUVWXYZÁÀÂÃÉÊÍÓÔÕÚÇ'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-multilingual-cased')\n",
    "model = BertForMaskedLM.from_pretrained('bert-base-multilingual-cased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_dict=torch.load('../../models/carolina/end_token/best_model.pt', map_location='cuda:1')\n",
    "model.load_state_dict(state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get sentences\n",
    "df = load_dataset('carolmou/random-sentences')['test']\n",
    "sentences = df['correct_text']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create function with specified tokenizer, model and device\n",
    "get_all_predictions = create_functions(tokenizer, model, 'cuda:1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# matches all lower case words or word with the first upper character and hiphenized words\n",
    "reg = rf'\\b(?:[{upper_case}][{lower_case}]*|[{lower_case}]+(?:-[{lower_case}]+)*|[{lower_case}]*[{upper_case}](?=[{lower_case}]))\\b'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# of (sentence, last_word)\n",
    "data_pairs = []\n",
    "\n",
    "for sent in sentences:\n",
    "    # all words\n",
    "    words = list(re.finditer(reg, sent))\n",
    "\n",
    "    if not words:\n",
    "        continue\n",
    "\n",
    "    beg_index = words[-1].start()\n",
    "    sent_without_last = sent[:beg_index]\n",
    "    data_pairs.append((sent_without_last, words[-1].group()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_samples = len(data_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corrects = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_k = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_for_model():\n",
    "    # 'corrects' is a prefix sum array\n",
    "    corrects = [0] * top_k\n",
    "    loop = tqdm(data_pairs, total=total_samples, leave=True)\n",
    "\n",
    "    for sent, word in loop:\n",
    "        suggestions = get_all_predictions(sent,top_k, False)[:-1]\n",
    "        try:\n",
    "            # gotta add this extra space because\n",
    "            # the prediction of a new word also\n",
    "            # predicts a preceding whitespace\n",
    "            ix = suggestions.index(' '+word)\n",
    "        except:\n",
    "            continue\n",
    "\n",
    "        corrects[ix] += 1\n",
    "\n",
    "    tot = 0\n",
    "\n",
    "    # retrieve the actual value from the PSA\n",
    "    for ix, val in enumerate(corrects):\n",
    "        tot += val\n",
    "        print(f'Top {ix+1}: {tot}/{total_samples} = {tot/total_samples}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_for_model()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
