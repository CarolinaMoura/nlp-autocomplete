{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from masking_strategies import mask_random_positions, mask_end_positions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assure_CLS_and_SEP_false(id_tensor, true_false_tensor):\n",
    "    \"\"\"\n",
    "    Receives a tensor of ids and a tensor of masking, with\n",
    "    True and False values. Returns a copy of the true_false_tensor\n",
    "    where every CLS and SEP position is for sure set to False.\n",
    "\n",
    "    Doesn't mutate any input value and it's free of aliasing.\n",
    "    \"\"\"\n",
    "    ans = true_false_tensor.detach().clone()\n",
    "    ans = ans & (id_tensor != CLS) & (id_tensor != SEP)\n",
    "    return ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mask(masking_strategy, tensor):\n",
    "    \"\"\"\n",
    "    Mutates tensor accordingly to the masking_strategy.\n",
    "    \n",
    "    Args:\n",
    "        masking_strategy: strategy to create the masked\n",
    "                          input_id.\n",
    "        tensor: tensor of tensors, the last representing\n",
    "                the tokenized inputs.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    shape = tensor.shape\n",
    "    mask_arr = masking_strategy(tensor)\n",
    "    mask_arr = assure_CLS_and_SEP_false(tensor, mask_arr)\n",
    "    rows = shape[0]\n",
    "\n",
    "    def indices_to_mask(idx):\n",
    "        \"\"\"\n",
    "        Returns a list containing all positions in the\n",
    "        idx-th row of mask_arr that have to be masked.\n",
    "\n",
    "        0 <= idx < rows has to be satisfied.\n",
    "        \"\"\"\n",
    "        to_mask_positions = mask_arr[idx].nonzero()\n",
    "        return torch.flatten(to_mask_positions).tolist()\n",
    "\n",
    "    for i in range(rows):\n",
    "        selection = indices_to_mask(i)\n",
    "        tensor[i, selection] = MASKED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_labels_and_ids(\n",
    "    sentences: list[str], path_to_save: str, masking_strategy: function\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    Saves the dictionary of input_ids, labels and attention_mask\n",
    "    to memory at the specified path.\n",
    "    \"\"\"\n",
    "\n",
    "    # get rid of empty sentences\n",
    "    sentences = [sent for sent in sentences if sent]\n",
    "\n",
    "    inputs = tokenizer(\n",
    "        sentences,\n",
    "        return_tensors=\"pt\",\n",
    "        max_length=tokenizer.model_max_length,\n",
    "        padding=True,\n",
    "        truncation=True,\n",
    "    )\n",
    "\n",
    "    # \"labels\" is the answer key\n",
    "    inputs[\"labels\"] = inputs[\"input_ids\"].detach().clone()\n",
    "\n",
    "    # corrupt \"input_ids\"\n",
    "    mask(masking_strategy, inputs[\"input_ids\"])\n",
    "\n",
    "    torch.save(\n",
    "        {\n",
    "            \"labels\": inputs[\"labels\"],\n",
    "            \"input_ids\": inputs[\"input_ids\"],\n",
    "            \"attention_mask\": inputs[\"attention_mask\"],\n",
    "        },\n",
    "        f\"{path}\",\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
